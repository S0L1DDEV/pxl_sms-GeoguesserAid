{
  "best_global_step": 2813,
  "best_metric": 1.8892890214920044,
  "best_model_checkpoint": "./checkpoints\\checkpoint-2813",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2813,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017774617845716316,
      "grad_norm": 45.72555160522461,
      "learning_rate": 8.709562744400995e-07,
      "loss": 5.1679,
      "step": 50
    },
    {
      "epoch": 0.03554923569143263,
      "grad_norm": 37.387176513671875,
      "learning_rate": 1.7596871667259156e-06,
      "loss": 4.3626,
      "step": 100
    },
    {
      "epoch": 0.053323853537148955,
      "grad_norm": 39.64204788208008,
      "learning_rate": 2.6484180590117313e-06,
      "loss": 3.6069,
      "step": 150
    },
    {
      "epoch": 0.07109847138286526,
      "grad_norm": 40.33796310424805,
      "learning_rate": 3.5371489512975476e-06,
      "loss": 3.3746,
      "step": 200
    },
    {
      "epoch": 0.08887308922858159,
      "grad_norm": 44.7415657043457,
      "learning_rate": 4.425879843583363e-06,
      "loss": 3.0482,
      "step": 250
    },
    {
      "epoch": 0.10664770707429791,
      "grad_norm": 66.34918975830078,
      "learning_rate": 5.314610735869179e-06,
      "loss": 2.9366,
      "step": 300
    },
    {
      "epoch": 0.12442232492001422,
      "grad_norm": 57.899330139160156,
      "learning_rate": 6.2033416281549945e-06,
      "loss": 2.7185,
      "step": 350
    },
    {
      "epoch": 0.14219694276573053,
      "grad_norm": 56.05861282348633,
      "learning_rate": 7.092072520440811e-06,
      "loss": 2.6071,
      "step": 400
    },
    {
      "epoch": 0.15997156061144685,
      "grad_norm": 59.65100860595703,
      "learning_rate": 7.980803412726627e-06,
      "loss": 2.4038,
      "step": 450
    },
    {
      "epoch": 0.17774617845716317,
      "grad_norm": 59.519691467285156,
      "learning_rate": 8.869534305012443e-06,
      "loss": 2.4168,
      "step": 500
    },
    {
      "epoch": 0.1955207963028795,
      "grad_norm": 51.024356842041016,
      "learning_rate": 9.758265197298258e-06,
      "loss": 2.3297,
      "step": 550
    },
    {
      "epoch": 0.21329541414859582,
      "grad_norm": 51.21497344970703,
      "learning_rate": 1.0646996089584074e-05,
      "loss": 2.1683,
      "step": 600
    },
    {
      "epoch": 0.23107003199431211,
      "grad_norm": 55.06470489501953,
      "learning_rate": 1.1535726981869891e-05,
      "loss": 2.199,
      "step": 650
    },
    {
      "epoch": 0.24884464984002844,
      "grad_norm": 53.37484359741211,
      "learning_rate": 1.2424457874155706e-05,
      "loss": 2.1537,
      "step": 700
    },
    {
      "epoch": 0.26661926768574473,
      "grad_norm": 43.10935974121094,
      "learning_rate": 1.3313188766441524e-05,
      "loss": 2.0608,
      "step": 750
    },
    {
      "epoch": 0.28439388553146105,
      "grad_norm": 57.46440887451172,
      "learning_rate": 1.4201919658727339e-05,
      "loss": 2.036,
      "step": 800
    },
    {
      "epoch": 0.3021685033771774,
      "grad_norm": 37.48624801635742,
      "learning_rate": 1.5090650551013155e-05,
      "loss": 2.0457,
      "step": 850
    },
    {
      "epoch": 0.3199431212228937,
      "grad_norm": 53.04494094848633,
      "learning_rate": 1.5979381443298968e-05,
      "loss": 1.8508,
      "step": 900
    },
    {
      "epoch": 0.33771773906861,
      "grad_norm": 68.19896697998047,
      "learning_rate": 1.6868112335584785e-05,
      "loss": 1.9957,
      "step": 950
    },
    {
      "epoch": 0.35549235691432635,
      "grad_norm": 70.56356811523438,
      "learning_rate": 1.77568432278706e-05,
      "loss": 1.9539,
      "step": 1000
    },
    {
      "epoch": 0.37326697476004267,
      "grad_norm": 49.84227752685547,
      "learning_rate": 1.8645574120156416e-05,
      "loss": 1.8547,
      "step": 1050
    },
    {
      "epoch": 0.391041592605759,
      "grad_norm": 43.23459243774414,
      "learning_rate": 1.9534305012442234e-05,
      "loss": 1.886,
      "step": 1100
    },
    {
      "epoch": 0.4088162104514753,
      "grad_norm": 42.602691650390625,
      "learning_rate": 2.042303590472805e-05,
      "loss": 2.0184,
      "step": 1150
    },
    {
      "epoch": 0.42659082829719164,
      "grad_norm": 37.47589874267578,
      "learning_rate": 2.1311766797013865e-05,
      "loss": 1.792,
      "step": 1200
    },
    {
      "epoch": 0.4443654461429079,
      "grad_norm": 57.8959846496582,
      "learning_rate": 2.2200497689299682e-05,
      "loss": 2.0696,
      "step": 1250
    },
    {
      "epoch": 0.46214006398862423,
      "grad_norm": 44.53250503540039,
      "learning_rate": 2.30892285815855e-05,
      "loss": 1.7371,
      "step": 1300
    },
    {
      "epoch": 0.47991468183434055,
      "grad_norm": 37.292388916015625,
      "learning_rate": 2.3977959473871313e-05,
      "loss": 1.9644,
      "step": 1350
    },
    {
      "epoch": 0.4976892996800569,
      "grad_norm": 51.556644439697266,
      "learning_rate": 2.4866690366157127e-05,
      "loss": 1.8969,
      "step": 1400
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 46.945472717285156,
      "learning_rate": 2.5755421258442947e-05,
      "loss": 1.9427,
      "step": 1450
    },
    {
      "epoch": 0.5332385353714895,
      "grad_norm": 53.55520248413086,
      "learning_rate": 2.6644152150728764e-05,
      "loss": 1.9012,
      "step": 1500
    },
    {
      "epoch": 0.5510131532172058,
      "grad_norm": 34.33576583862305,
      "learning_rate": 2.7532883043014578e-05,
      "loss": 1.8628,
      "step": 1550
    },
    {
      "epoch": 0.5687877710629221,
      "grad_norm": 35.07330322265625,
      "learning_rate": 2.8421613935300395e-05,
      "loss": 1.9381,
      "step": 1600
    },
    {
      "epoch": 0.5865623889086384,
      "grad_norm": 32.17849349975586,
      "learning_rate": 2.9310344827586206e-05,
      "loss": 1.8474,
      "step": 1650
    },
    {
      "epoch": 0.6043370067543548,
      "grad_norm": 40.79207229614258,
      "learning_rate": 3.0199075719872023e-05,
      "loss": 1.8367,
      "step": 1700
    },
    {
      "epoch": 0.6221116246000711,
      "grad_norm": 47.2532844543457,
      "learning_rate": 3.108780661215784e-05,
      "loss": 1.9656,
      "step": 1750
    },
    {
      "epoch": 0.6398862424457874,
      "grad_norm": 35.42753601074219,
      "learning_rate": 3.197653750444366e-05,
      "loss": 2.0286,
      "step": 1800
    },
    {
      "epoch": 0.6576608602915037,
      "grad_norm": 32.47238540649414,
      "learning_rate": 3.286526839672947e-05,
      "loss": 1.8215,
      "step": 1850
    },
    {
      "epoch": 0.67543547813722,
      "grad_norm": 40.022151947021484,
      "learning_rate": 3.3753999289015285e-05,
      "loss": 1.8714,
      "step": 1900
    },
    {
      "epoch": 0.6932100959829364,
      "grad_norm": 39.149559020996094,
      "learning_rate": 3.46427301813011e-05,
      "loss": 1.9406,
      "step": 1950
    },
    {
      "epoch": 0.7109847138286527,
      "grad_norm": 49.03817367553711,
      "learning_rate": 3.553146107358692e-05,
      "loss": 1.8984,
      "step": 2000
    },
    {
      "epoch": 0.728759331674369,
      "grad_norm": 30.21510124206543,
      "learning_rate": 3.6420191965872736e-05,
      "loss": 1.9127,
      "step": 2050
    },
    {
      "epoch": 0.7465339495200853,
      "grad_norm": 33.946224212646484,
      "learning_rate": 3.7308922858158554e-05,
      "loss": 1.9328,
      "step": 2100
    },
    {
      "epoch": 0.7643085673658017,
      "grad_norm": 38.04575729370117,
      "learning_rate": 3.819765375044437e-05,
      "loss": 1.8885,
      "step": 2150
    },
    {
      "epoch": 0.782083185211518,
      "grad_norm": 42.14911651611328,
      "learning_rate": 3.908638464273018e-05,
      "loss": 1.8715,
      "step": 2200
    },
    {
      "epoch": 0.7998578030572343,
      "grad_norm": 34.796913146972656,
      "learning_rate": 3.9975115535016e-05,
      "loss": 1.9713,
      "step": 2250
    },
    {
      "epoch": 0.8176324209029506,
      "grad_norm": 35.36799240112305,
      "learning_rate": 4.0863846427301816e-05,
      "loss": 1.9537,
      "step": 2300
    },
    {
      "epoch": 0.835407038748667,
      "grad_norm": 31.833845138549805,
      "learning_rate": 4.175257731958763e-05,
      "loss": 1.986,
      "step": 2350
    },
    {
      "epoch": 0.8531816565943833,
      "grad_norm": 31.480195999145508,
      "learning_rate": 4.264130821187345e-05,
      "loss": 1.9089,
      "step": 2400
    },
    {
      "epoch": 0.8709562744400995,
      "grad_norm": 28.059268951416016,
      "learning_rate": 4.353003910415927e-05,
      "loss": 1.9828,
      "step": 2450
    },
    {
      "epoch": 0.8887308922858158,
      "grad_norm": 33.97496032714844,
      "learning_rate": 4.4418769996445084e-05,
      "loss": 1.9426,
      "step": 2500
    },
    {
      "epoch": 0.9065055101315321,
      "grad_norm": 30.06556510925293,
      "learning_rate": 4.5307500888730895e-05,
      "loss": 1.8499,
      "step": 2550
    },
    {
      "epoch": 0.9242801279772485,
      "grad_norm": 21.399444580078125,
      "learning_rate": 4.6196231781016705e-05,
      "loss": 1.8867,
      "step": 2600
    },
    {
      "epoch": 0.9420547458229648,
      "grad_norm": 31.51189613342285,
      "learning_rate": 4.708496267330252e-05,
      "loss": 2.0231,
      "step": 2650
    },
    {
      "epoch": 0.9598293636686811,
      "grad_norm": 35.6729850769043,
      "learning_rate": 4.797369356558834e-05,
      "loss": 1.836,
      "step": 2700
    },
    {
      "epoch": 0.9776039815143974,
      "grad_norm": 28.56304931640625,
      "learning_rate": 4.886242445787416e-05,
      "loss": 1.9399,
      "step": 2750
    },
    {
      "epoch": 0.9953785993601137,
      "grad_norm": 39.50929641723633,
      "learning_rate": 4.9751155350159974e-05,
      "loss": 1.8985,
      "step": 2800
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.8892890214920044,
      "eval_runtime": 579.9912,
      "eval_samples_per_second": 8.621,
      "eval_steps_per_second": 0.54,
      "step": 2813
    }
  ],
  "logging_steps": 50,
  "max_steps": 28130,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.77255879496541e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
